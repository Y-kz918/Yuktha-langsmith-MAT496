{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4uJnqOM_Nk"
      },
      "source": [
        "# Dataset Upload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYgIYKyxM_Nm"
      },
      "source": [
        "In addition to creating and editing Datasets in the LangSmith UI, you can also create and edit datasets with the LangSmith SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alDJSRkEM_Nn"
      },
      "source": [
        "Let's go ahead an upload a list of examples that we have from our RAG application to LangSmith as a new dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZZ99RTzM_Nn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"   \n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwec7oiPM_No"
      },
      "outputs": [],
      "source": [
        "\n",
        "from groq import Groq   \n",
        "\n",
        "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWJp_xV5Oejt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "from langsmith import traceable\n",
        "\n",
        "\n",
        "groq_client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "@traceable\n",
        "def langsmith_rag(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Simple RAG-style call using Groq as the LLM.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions clearly.\"},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "\n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"openai/gpt-oss-120b\",   \n",
        "        messages=messages,\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content   \n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE2gsWJgM_No",
        "outputId": "1798438d-6893-44e2-8829-d9739e477330"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'example_ids': ['3f5af433-5a4e-4e61-a355-f6ac78d98a7c',\n",
              "  '77eb4d8d-5621-46f6-be4e-3fa8c235d0eb',\n",
              "  '8ae3fc92-2b18-4ea9-ba01-ed1618cc5e3f',\n",
              "  '4b66882f-a29c-4d72-8419-120270bed93a',\n",
              "  '225bc0a7-9c8f-4e61-925a-7e974bd34780',\n",
              "  '2c53c635-bf6d-427b-b1a6-0812fd1875b3',\n",
              "  '62d9d7e2-2b18-4a24-a159-9f64bdbb3d20',\n",
              "  'c8ad1754-24d9-4da4-bbe4-5fe3460d0b46',\n",
              "  '3aeef2d3-aaaa-41ad-bf5f-bafdc8eff56a',\n",
              "  '88b214f4-9110-483f-ae41-aaf2db04ea04'],\n",
              " 'count': 10}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "example_inputs = [\n",
        "(\"How do I set up tracing to LangSmith if I'm using LangChain?\", \"To set up tracing to LangSmith while using LangChain, you need to set the environment variable `LANGSMITH_TRACING` to 'true'. Additionally, you must set the `LANGSMITH_API_KEY` environment variable to your API key. By default, traces will be logged to a project named \\\"default.\\\"\"),\n",
        "(\"How can I trace with the @traceable decorator?\", \"To trace with the @traceable decorator in Python, simply decorate any function you want to log traces for by adding `@traceable` above the function definition. Ensure that the LANGSMITH_TRACING environment variable is set to 'true' to enable tracing, and also set the LANGSMITH_API_KEY environment variable with your API key. By default, traces will be logged to a project named \\\"default,\\\" but you can configure it to log to a different project if needed.\"),\n",
        "(\"How do I pass metadata in with @traceable?\", \"You can pass metadata with the @traceable decorator by specifying arbitrary key-value pairs as arguments. This allows you to associate additional information, such as the execution environment or user details, with your traces. For more detailed instructions, refer to the LangSmith documentation on adding metadata and tags.\"),\n",
        "(\"What is LangSmith used for in three sentences?\", \"LangSmith is a platform designed for the development, monitoring, and testing of LLM applications. It enables users to collect and analyze unstructured data, debug issues, and create datasets for testing and evaluation. The tool supports various workflows throughout the application development lifecycle, enhancing the overall performance and reliability of LLM applications.\"),\n",
        "(\"What testing capabilities does LangSmith have?\", \"LangSmith offers capabilities for creating datasets of inputs and reference outputs to run tests on LLM applications, supporting a test-driven approach. It allows for bulk uploads of test cases, on-the-fly creation, and exporting from application traces. Additionally, LangSmith facilitates custom evaluations to score test results, enhancing the testing process.\"),\n",
        "(\"Does LangSmith support online evaluation?\", \"Yes, LangSmith supports online evaluation as a feature. It allows you to configure a sample of runs from production to be evaluated, providing feedback on those runs. You can use either custom code or an LLM as a judge for the evaluations.\"),\n",
        "(\"Does LangSmith support offline evaluation?\", \"Yes, LangSmith supports offline evaluation through its evaluation how-to guides and features for managing datasets. Users can manage datasets for offline evaluations and run various types of evaluations, including unit testing and auto-evaluation. This allows for comprehensive testing and improvement of LLM applications.\"),\n",
        "(\"Can LangSmith be used for finetuning and model training?\", \"Yes, LangSmith can be used for fine-tuning and model training. It allows you to capture run traces from your deployment, query and filter this data, and convert it into a format suitable for fine-tuning models. Additionally, you can create training datasets to keep track of the data used for model training.\"),\n",
        "(\"Can LangSmith be used to evaluate agents?\", \"Yes, LangSmith can be used to evaluate agents. It provides various evaluation strategies, including assessing the agent's final response, evaluating individual steps, and analyzing the trajectory of tool calls. These methods help ensure the effectiveness of LLM applications.\"),\n",
        "(\"How do I create user feedback with the LangSmith sdk?\", \"To create user feedback with the LangSmith SDK, you first need to run your application and obtain the `run_id`. Then, you can use the `create_feedback` method, providing the `run_id`, a feedback key, a score, and an optional comment. For example, in Python, it would look like this: `client.create_feedback(run_id, key=\\\"feedback-key\\\", score=1.0, comment=\\\"comment\\\")`.\"),\n",
        "]\n",
        "\n",
        "client = Client()\n",
        "# TODO: Fill in dataset id\n",
        "dataset_id = \"ecf95159-4a0b-4e91-9087-c4f048dec756\"\n",
        "\n",
        "# Prepare inputs and outputs for bulk creation\n",
        "inputs = [{\"question\": input_prompt} for input_prompt, _ in example_inputs]\n",
        "outputs = [{\"output\": output_answer} for _, output_answer in example_inputs]\n",
        "\n",
        "client.create_examples(\n",
        "  inputs=inputs,\n",
        "  outputs=outputs,\n",
        "  dataset_name=\"Golden Dataset\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-LO-BUXOSJi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cALyn3BvM_Nq"
      },
      "source": [
        "## Submitting another Trace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KgHYLy1M_Nq"
      },
      "source": [
        "I've moved our RAG application definition to `app.py` so we can quickly import it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7iVs497M_Nq",
        "outputId": "264df7da-314c-493c-fd85-c7b1b29916c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Below is a quick, language‑agnostic cheat‑sheet that shows **exactly how you give extra key/value data (metadata) to a trace when you use the `@traceble` decorator**.  \n",
            "The pattern is the same no matter whether you are in Python, Java, or JavaScript/TypeScript – you simply pass a map/​object of attributes to the decorator, and the tracing library will attach those attributes to the span that it creates for the wrapped function.\n",
            "\n",
            "---\n",
            "\n",
            "## 1. What `@traceble` Does (in a nutshell)\n",
            "\n",
            "| Step | What happens | Where the metadata ends up |\n",
            "|------|--------------|----------------------------|\n",
            "| 1️⃣ | The decorator creates a **span** (or a similar tracing unit) when the function is entered. | In the tracing backend (Jaeger, Zipkin, Lightstep, Cloud‑Trace, etc.) as a span. |\n",
            "| 2️⃣ | When you supply a `metadata` argument, the library **adds each key/value pair as an attribute** on that span. | Visible in the UI under “Attributes” (or “Tags”). |\n",
            "| 3️⃣ | The span is closed when the function returns (or throws). | The attributes stay attached for the whole life of the span. |\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Python (most common use‑case)\n",
            "\n",
            "### Install the library (example)\n",
            "\n",
            "```bash\n",
            "pip install traceble   # or pip install opentelemetry-instrumentation‑traceble\n",
            "```\n",
            "\n",
            "### Basic usage – no metadata\n",
            "\n",
            "```python\n",
            "from traceble import traceble\n",
            "\n",
            "@traceble\n",
            "def hello(name: str):\n",
            "    return f\"Hi {name}\"\n",
            "```\n",
            "\n",
            "### Adding metadata\n",
            "\n",
            "```python\n",
            "from traceble import traceble\n",
            "\n",
            "@traceble(metadata={\"user.id\": \"12345\", \"feature\": \"beta\", \"debug\": True})\n",
            "def process_order(order_id: str, amount: float):\n",
            "    # … your business logic …\n",
            "    return \"OK\"\n",
            "```\n",
            "\n",
            "* The `metadata` argument must be a **mapping** (`dict`, `Mapping`, …).  \n",
            "* Keys are strings, values can be any primitive that the tracer can serialize (str, int, bool, float).\n",
            "\n",
            "### Dynamic metadata (e.g. values only known at call‑time)\n",
            "\n",
            "If you need the metadata to depend on the function arguments, you can use a **callable** that returns a dict:\n",
            "\n",
            "```python\n",
            "def order_meta(order_id, amount):\n",
            "    return {\n",
            "        \"order.id\": order_id,\n",
            "        \"order.amount\": amount,\n",
            "        \"currency\": \"USD\"\n",
            "    }\n",
            "\n",
            "@traceble(metadata=order_meta)   # <-- pass the callable, not the dict itself\n",
            "def process_order(order_id: str, amount: float):\n",
            "    …\n",
            "```\n",
            "\n",
            "The decorator will call `order_meta(*args, **kwargs)` right before the span is started, and the returned dict will be attached to the span.\n",
            "\n",
            "### Accessing the span inside the function (optional)\n",
            "\n",
            "Some libraries expose the active span via context, so you can add more attributes later:\n",
            "\n",
            "```python\n",
            "from traceble import traceble, get_current_span\n",
            "\n",
            "@traceble(metadata={\"handler\": \"process_order\"})\n",
            "def process_order(order_id: str, amount: float):\n",
            "    span = get_current_span()          # <-- Grab the live span\n",
            "    span.set_attribute(\"order.id\", order_id)\n",
            "    # … more work …\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "## 3. Java (Spring / OpenTelemetry)\n",
            "\n",
            "```java\n",
            "import io.opentelemetry.api.trace.Span;\n",
            "import io.opentelemetry.api.trace.Tracer;\n",
            "import io.opentelemetry.extension.annotations.Traceable; // fictitious package name\n",
            "\n",
            "// Static tracer (usually injected)\n",
            "private static final Tracer tracer = GlobalOpenTelemetry.getTracer(\"my-app\");\n",
            "\n",
            "@Traceable(metadata = {\n",
            "        @Attribute(key = \"service.name\", value = \"order-service\"),\n",
            "        @Attribute(key = \"environment\", value = \"staging\")\n",
            "})\n",
            "public String processOrder(String orderId, double amount) {\n",
            "    // The span is already created and the attributes above are attached.\n",
            "    // You can add more at runtime:\n",
            "    Span.current().setAttribute(\"order.id\", orderId);\n",
            "    // …\n",
            "    return \"OK\";\n",
            "}\n",
            "```\n",
            "\n",
            "* `metadata` is an **array of `@Attribute` annotations**.  \n",
            "* If you need dynamic values, the library also lets you implement `TraceableMetadataProvider`:\n",
            "\n",
            "```java\n",
            "@Traceable(metadataProvider = OrderMetadataProvider.class)\n",
            "public String processOrder(String orderId, double amount) { … }\n",
            "\n",
            "public class OrderMetadataProvider implements TraceableMetadataProvider {\n",
            "    @Override\n",
            "    public Map<String, String> provide(Object[] args) {\n",
            "        String orderId = (String) args[0];\n",
            "        Double amount = (Double) args[1];\n",
            "        return Map.of(\n",
            "            \"order.id\", orderId,\n",
            "            \"order.amount\", amount.toString()\n",
            "        );\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "## 4. JavaScript / TypeScript (Node.js)\n",
            "\n",
            "Most Node libraries expose `@traceble` as a decorator factory that accepts an **options object**.\n",
            "\n",
            "```ts\n",
            "import { traceble } from '@traceble/opentelemetry';\n",
            "\n",
            "// Static metadata (compile‑time known)\n",
            "class OrderService {\n",
            "  @traceble({ metadata: { service: 'order', env: 'prod' } })\n",
            "  async process(orderId: string, amount: number) {\n",
            "    // …\n",
            "    return 'OK';\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "### Dynamic metadata\n",
            "\n",
            "```ts\n",
            "function orderMetadata(args: any[]) {\n",
            "  const [orderId, amount] = args;\n",
            "  return {\n",
            "    'order.id': orderId,\n",
            "    'order.amount': amount,\n",
            "    'currency': 'USD',\n",
            "  };\n",
            "}\n",
            "\n",
            "class OrderService {\n",
            "  @traceble({ metadata: orderMetadata })\n",
            "  async process(orderId: string, amount: number) {\n",
            "    // …\n",
            "    return 'OK';\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "* The `metadata` field can be **either a plain object** or **a function** that receives the original argument list and returns an object.\n",
            "\n",
            "### Adding attributes later in the function\n",
            "\n",
            "```ts\n",
            "import { trace } from '@opentelemetry/api';\n",
            "\n",
            "class OrderService {\n",
            "  @traceble()\n",
            "  async process(orderId: string, amount: number) {\n",
            "    const span = trace.getSpan(trace.context.active());\n",
            "    span?.setAttribute('order.id', orderId);\n",
            "    // …\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "## 5. Common Pitfalls & Gotchas\n",
            "\n",
            "| Symptom | Likely cause | Fix |\n",
            "|---------|--------------|-----|\n",
            "| Metadata never appears in the UI | You passed a **list** instead of a dict/object, or the key/value types are unsupported. | Use a plain `dict`/`Map`/`object` with **string keys** and primitive values. |\n",
            "| Dynamic metadata function is called **twice** (once on import, once at runtime) | You invoked the function when defining the decorator (`@traceble(metadata=make_meta())`). | Pass the **function itself**, not its result: `@traceble(metadata=make_meta)`. |\n",
            "| Attributes are missing when an exception is raised | The library may close the span **before** you have a chance to add extra attributes in a `finally` block. | Add all needed attributes **before** the first possible exception, or use a `try/except/finally` that sets them in the `finally`. |\n",
            "| Too many attributes → trace rejected | Some back‑ends limit the number or size of attributes per span. | Keep metadata small (≤ 32 KB total) and avoid per‑request high‑cardinality values (e.g., full request bodies). |\n",
            "| Attributes show up under a different name (e.g., `metadata.key` instead of `key`) | The library prefixes metadata automatically (common in some SDKs). | Check the library docs – you can usually disable the prefix via a config flag (`prefix: ''`). |\n",
            "\n",
            "---\n",
            "\n",
            "## 6. TL;DR – One‑liner cheat sheet\n",
            "\n",
            "| Language | Syntax |\n",
            "|----------|--------|\n",
            "| **Python** | `@traceble(metadata={\"key\": \"value\", \"user.id\": user_id})` |\n",
            "| **Python (dynamic)** | `@traceble(metadata=my_meta_func)` where `my_meta_func(*args, **kwargs) -> dict` |\n",
            "| **Java** | `@Traceable(metadata = {@Attribute(key=\"k\", value=\"v\")})` |\n",
            "| **Java (dynamic)** | `@Traceable(metadataProvider = MyProvider.class)` |\n",
            "| **Node / TS** | `@traceble({ metadata: { k: \"v\" } })` |\n",
            "| **Node / TS (dynamic)** | `@traceble({ metadata: myMetaFn })` where `myMetaFn(args) -> object` |\n",
            "\n",
            "---\n",
            "\n",
            "### Quick “copy‑paste” example (Python)\n",
            "\n",
            "```python\n",
            "from traceble import traceble, get_current_span\n",
            "\n",
            "def dynamic_meta(order_id, amount):\n",
            "    return {\n",
            "        \"order.id\": order_id,\n",
            "        \"order.amount\": str(amount),\n",
            "        \"env\": \"prod\"\n",
            "    }\n",
            "\n",
            "@traceble(metadata=dynamic_meta)          # <-- passes metadata to the span\n",
            "def process_order(order_id: str, amount: float):\n",
            "    span = get_current_span()\n",
            "    span.set_attribute(\"handler\", \"process_order\")   # extra attribute at runtime\n",
            "    # … business logic …\n",
            "    return \"done\"\n",
            "```\n",
            "\n",
            "Run your service, generate a few traces, and you’ll see **`order.id`**, **`order.amount`**, **`env`**, and **`handler`** listed under the span’s attributes.\n",
            "\n",
            "---\n",
            "\n",
            "## 7. Where to Look for More Details\n",
            "\n",
            "| SDK | Docs URL |\n",
            "|-----|----------|\n",
            "| Python (`traceble`) | https://pypi.org/project/traceble/ (search “metadata” in the README) |\n",
            "| OpenTelemetry Python | https://opentelemetry.io/docs/instrumentation/python/automatic/ |\n",
            "| Java (`@Traceable`) | https://github.com/open-telemetry/opentelemetry-java/tree/main/sdk/trace |\n",
            "| Node (`@traceble`) | https://github.com/open-telemetry/opentelemetry-js/tree/main/packages/opentelemetry-instrumentation |\n",
            "\n",
            "If you tell me which language / SDK you’re actually using, I can give you an even more tailored snippet. Happy tracing!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "question = \"How do I pass metadata using @traceble?\"\n",
        "answer = langsmith_rag(question)\n",
        "\n",
        "print(\"Answer:\", answer)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ls-academy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
